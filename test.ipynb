{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.21.0\n",
      "  Using cached numpy-1.21.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting pandasai\n",
      "  Using cached pandasai-2.2.15-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/annasand/apps/.venv/lib/python3.9/site-packages (from pandas==1.5.3) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas==1.5.3)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting astor<0.9.0,>=0.8.1 (from pandasai)\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting duckdb<2.0.0,>=1.0.0 (from pandasai)\n",
      "  Using cached duckdb-1.1.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (762 bytes)\n",
      "Collecting faker<20.0.0,>=19.12.0 (from pandasai)\n",
      "  Using cached Faker-19.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.3 (from pandasai)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting matplotlib<4.0.0,>=3.7.1 (from pandasai)\n",
      "  Using cached matplotlib-3.9.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting openai<2 (from pandasai)\n",
      "  Using cached openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pillow<11.0.0,>=10.1.0 (from pandasai)\n",
      "  Using cached pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting pydantic<3,>=1 (from pandasai)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from pandasai)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting requests<3.0.0,>=2.31.0 (from pandasai)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting scipy<2.0.0,>=1.9.0 (from pandasai)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting sqlalchemy<3,>=1.4 (from pandasai)\n",
      "  Using cached SQLAlchemy-2.0.35-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting sqlglot<26.0.0,>=25.0.3 (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai)\n",
      "  Using cached sqlglot-25.24.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.3->pandasai)\n",
      "  Using cached MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4.0.0,>=3.7.1->pandasai)\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<4.0.0,>=3.7.1->pandasai)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4.0.0,>=3.7.1->pandasai)\n",
      "  Using cached fonttools-4.54.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib<4.0.0,>=3.7.1->pandasai)\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib<4.0.0,>=3.7.1 (from pandasai)\n",
      "  Using cached matplotlib-3.9.1.post1-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.9.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.8.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/annasand/apps/.venv/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (24.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4.0.0,>=3.7.1->pandasai)\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib<4.0.0,>=3.7.1->pandasai)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2->pandasai)\n",
      "  Using cached anyio-4.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2->pandasai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2->pandasai)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2->pandasai)\n",
      "  Using cached jiter-0.5.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting sniffio (from openai<2->pandasai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2->pandasai)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/annasand/apps/.venv/lib/python3.9/site-packages (from openai<2->pandasai) (4.12.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1->pandasai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1->pandasai)\n",
      "  Using cached pydantic_core-2.23.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/annasand/apps/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.31.0->pandasai)\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.31.0->pandasai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.31.0->pandasai)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.31.0->pandasai)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy<2.0.0,>=1.9.0 (from pandasai)\n",
      "  Using cached scipy-1.13.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.4-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.3-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.2-cp39-cp39-macosx_12_0_arm64.whl.metadata (54 kB)\n",
      "  Using cached scipy-1.11.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (54 kB)\n",
      "  Using cached scipy-1.10.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (53 kB)\n",
      "Collecting sqlglotrs==0.2.12 (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai)\n",
      "  Using cached sqlglotrs-0.2.12-cp39-cp39-macosx_11_0_arm64.whl.metadata (546 bytes)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/annasand/apps/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2->pandasai) (1.2.2)\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4.0.0,>=3.7.1->pandasai)\n",
      "  Using cached contourpy-1.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2->pandasai)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2->pandasai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/annasand/apps/.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib<4.0.0,>=3.7.1->pandasai) (3.20.2)\n",
      "Using cached numpy-1.21.0-cp39-cp39-macosx_11_0_arm64.whl (12.1 MB)\n",
      "Using cached pandas-1.5.3-cp39-cp39-macosx_11_0_arm64.whl (11.0 MB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached pandasai-2.2.15-py3-none-any.whl (182 kB)\n",
      "Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Using cached duckdb-1.1.1-cp39-cp39-macosx_12_0_arm64.whl (15.5 MB)\n",
      "Using cached Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached matplotlib-3.8.4-cp39-cp39-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Using cached openai-1.50.2-py3-none-any.whl (382 kB)\n",
      "Using cached pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.10.1-cp39-cp39-macosx_12_0_arm64.whl (28.9 MB)\n",
      "Using cached SQLAlchemy-2.0.35-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached sqlglot-25.24.0-py3-none-any.whl (415 kB)\n",
      "Using cached sqlglotrs-0.2.12-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.6.0-py3-none-any.whl (89 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n",
      "Using cached contourpy-1.2.1-cp39-cp39-macosx_11_0_arm64.whl (244 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached fonttools-4.54.1-cp39-cp39-macosx_11_0_arm64.whl (2.3 MB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached jiter-0.5.0-cp39-cp39-macosx_11_0_arm64.whl (283 kB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: pytz, urllib3, tqdm, sqlglotrs, sqlglot, sqlalchemy, sniffio, pyyaml, python-dotenv, pyparsing, pydantic-core, pillow, numpy, MarkupSafe, kiwisolver, jiter, importlib-resources, idna, h11, fonttools, duckdb, distro, cycler, charset-normalizer, certifi, astor, annotated-types, scipy, requests, pydantic, pandas, jinja2, httpcore, faker, contourpy, anyio, matplotlib, httpx, openai, pandasai\n",
      "Successfully installed MarkupSafe-2.1.5 annotated-types-0.7.0 anyio-4.6.0 astor-0.8.1 certifi-2024.8.30 charset-normalizer-3.3.2 contourpy-1.2.1 cycler-0.12.1 distro-1.9.0 duckdb-1.1.1 faker-19.13.0 fonttools-4.54.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 idna-3.10 importlib-resources-6.4.5 jinja2-3.1.4 jiter-0.5.0 kiwisolver-1.4.7 matplotlib-3.8.4 numpy-1.21.0 openai-1.50.2 pandas-1.5.3 pandasai-2.2.15 pillow-10.4.0 pydantic-2.9.2 pydantic-core-2.23.4 pyparsing-3.1.4 python-dotenv-1.0.1 pytz-2024.2 pyyaml-6.0.2 requests-2.32.3 scipy-1.10.1 sniffio-1.3.1 sqlalchemy-2.0.35 sqlglot-25.24.0 sqlglotrs-0.2.12 tqdm-4.66.5 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.21.0 pandas==1.5.3 pyyaml pandasai tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import io\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from pandasai import Agent, SmartDataframe\n",
    "# from azure_openai import AzureOpenAI\n",
    "from pandasai.llm.openai import OpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set up pandas options to display more rows and columns for better clarity\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the average sales amount for each month?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**AI Response:**\n",
       "\n",
       "To calculate the average sales amount for each month, you'll first need to ensure that the `Purchase Date` column is in datetime format. Then, you can group the data by month and calculate the average `Total Price`.\n",
       "\n",
       "Here is the code to achieve this:\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "# Load the dataset\n",
       "df = pd.read_csv('electronic_sales_data.csv')\n",
       "\n",
       "# Convert the 'Purchase Date' column to datetime format\n",
       "df['Purchase Date'] = pd.to_datetime(df['Purchase Date'])\n",
       "\n",
       "# Add a new column 'Month' that represents the month of the purchase\n",
       "df['Month'] = df['Purchase Date'].dt.to_period('M')\n",
       "\n",
       "# Group by 'Month' and calculate the average 'Total Price'\n",
       "average_sales_per_month = df.groupby('Month')['Total Price'].mean()\n",
       "\n",
       "# Print the result\n",
       "print(average_sales_per_month)\n",
       "```\n",
       "\n",
       "This code will output the average sales amount for each month."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Code Executed:**\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "# Load the dataset\n",
       "df = pd.read_csv('electronic_sales_data.csv')\n",
       "\n",
       "# Convert the 'Purchase Date' column to datetime format\n",
       "df['Purchase Date'] = pd.to_datetime(df['Purchase Date'])\n",
       "\n",
       "# Add a new column 'Month' that represents the month of the purchase\n",
       "df['Month'] = df['Purchase Date'].dt.to_period('M')\n",
       "\n",
       "# Group by 'Month' and calculate the average 'Total Price'\n",
       "average_sales_per_month = df.groupby('Month')['Total Price'].mean()\n",
       "\n",
       "# Print the result\n",
       "print(average_sales_per_month)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Output:**\n",
       "\n",
       "```\n",
       "Month\n",
       "2023-09    2536.641000\n",
       "2023-10    2544.968551\n",
       "2023-11    2595.274956\n",
       "2023-12    2475.875413\n",
       "2024-01    3230.928487\n",
       "2024-02    3153.848218\n",
       "2024-03    3231.664711\n",
       "2024-04    3322.077443\n",
       "2024-05    3275.899868\n",
       "2024-06    3335.984787\n",
       "2024-07    3285.635757\n",
       "2024-08    3323.150946\n",
       "2024-09    3376.468579\n",
       "Freq: M, Name: Total Price, dtype: float64\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "# from pandasai.llm.openai import OpenAI  # Uncomment if using pandasai's OpenAI wrapper\n",
    "\n",
    "def generate_dataset_description(file_path, description=None, key_features=None):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Prepare each part for the template\n",
    "    columns = f\"**Column Names:**\\n\\n- \" + \"\\n- \".join(list(df.columns))\n",
    "    head = f\"**First 2 Rows of the DataFrame:**\\n\\n\" + tabulate(df.head(2), headers='keys', tablefmt='pipe')\n",
    "    \n",
    "    buffer = io.StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    info_str = buffer.getvalue()\n",
    "    info = f\"**DataFrame Info:**\\n\\n```\\n{info_str}\\n```\"\n",
    "    \n",
    "    types = f\"**Data Types:**\\n\\n\" + tabulate(df.dtypes.reset_index(), headers=['Column', 'Data Type'], tablefmt='pipe')\n",
    "    summary = f\"**Summary Statistics:**\\n\\n\" + tabulate(df.describe(), headers='keys', tablefmt='pipe')\n",
    "    null_sum = \"**Number of Nulls in Columns:**\\n\\n\" + \"\\n\".join([f\"- **{col}**: {count}\" for col, count in df.isnull().sum().items()])\n",
    "    dupe_sum = f\"**Number of Duplicate Rows:** {df.duplicated().sum()}\"\n",
    "    unique_sum = \"**Number of Unique Values in Columns:**\\n\\n\" + \"\\n\".join([f\"- **{col}**: {count}\" for col, count in df.nunique().items()])\n",
    "    \n",
    "    # Set default values for optional arguments\n",
    "    if description is None:\n",
    "        description = \"No description provided.\"\n",
    "    \n",
    "    if key_features is None:\n",
    "        key_features = \"No key features provided.\"\n",
    "    \n",
    "    # Format the output\n",
    "    system = '''\n",
    "    You are a data scientist tasked to explore a dataset and provide meaningful insights.\n",
    "    To do this you will use the pandas Python library. Based on the questions you are asked, you will write Python code that should answer that question when you run it.\n",
    "\n",
    "    Below are details about the dataset that will help you write the code. Consider the filename and column names when writing your response so the code works for this dataset.\n",
    "    Do not make up column names, only use details that are provided.\n",
    "\n",
    "    DATASET DETAILS\n",
    "    ---\n",
    "    FILENAME:\n",
    "    {file_path}\n",
    "\n",
    "    DESCRIPTION:\n",
    "    {description}\n",
    "\n",
    "    COLUMN NAMES:\n",
    "    {columns}\n",
    "\n",
    "    KEY COLUMNS:\n",
    "    {key_features}\n",
    "\n",
    "    HEAD:\n",
    "    {head}\n",
    "\n",
    "    SUMMARY:\n",
    "    {summary}\n",
    "\n",
    "    INFO:\n",
    "    {info}\n",
    "\n",
    "    NUMBER OF NULLS IN COLUMNS:\n",
    "    {null_sum}\n",
    "\n",
    "    NUMBER OF DUPLICATES IN COLUMNS:\n",
    "    {dupe_sum}\n",
    "\n",
    "    NUMBER OF UNIQUE VALUES IN COLUMNS:\n",
    "    {unique_sum}\n",
    "\n",
    "    If you are unable to write code for the given question, do the following:\n",
    "       1. Explain what would be needed to answer this question.\n",
    "       2. Give a suggestion on a better question to ask.\n",
    "    '''\n",
    "    \n",
    "    # Insert values into the placeholders\n",
    "    return system.format(\n",
    "        file_path=file_path,\n",
    "        description=description,\n",
    "        columns=columns,\n",
    "        key_features=key_features,\n",
    "        head=head,\n",
    "        summary=summary,\n",
    "        info=info,\n",
    "        null_sum=null_sum,\n",
    "        dupe_sum=dupe_sum,\n",
    "        unique_sum=unique_sum\n",
    "    )\n",
    "\n",
    "def execute_python_code(response):\n",
    "    # Regex to find code wrapped in ```python ``` blocks\n",
    "    code_match = re.search(r'```python(.*?)```', response, re.DOTALL)\n",
    "    \n",
    "    if code_match:\n",
    "        code = code_match.group(1).strip()  # Extract and clean the code\n",
    "        \n",
    "        # Capture the output of the code execution\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = io.StringIO()\n",
    "        \n",
    "        try:\n",
    "            # Execute the code\n",
    "            exec(code, globals())\n",
    "            \n",
    "            # Get the output from the code execution\n",
    "            output = sys.stdout.getvalue()\n",
    "            \n",
    "            # Check if there are any plots generated\n",
    "            plt.show()\n",
    "            \n",
    "            # Display the code, output, and any additional information\n",
    "            display(Markdown(f\"**Code Executed:**\\n\\n```python\\n{code}\\n```\"))\n",
    "            if output:\n",
    "                display(Markdown(f\"**Output:**\\n\\n```\\n{output}\\n```\"))\n",
    "        except Exception as e:\n",
    "            # Handle any exceptions that occur during code execution\n",
    "            output = f\"Error executing code: {e}\"\n",
    "            display(Markdown(f\"**Error:**\\n\\n```\\n{output}\\n```\"))\n",
    "        finally:\n",
    "            # Restore standard output to its original state\n",
    "            sys.stdout = old_stdout\n",
    "    else:\n",
    "        display(Markdown(\"**No Python code found in the response.**\" + response))\n",
    "\n",
    "def ask_question_and_display_output(question, file_path, description=None, key_features=None):\n",
    "    # Generate system message with dataset details\n",
    "    system_message = generate_dataset_description(file_path, description, key_features)\n",
    "    \n",
    "    # Initialize OpenAI (replace with your key and parameters)\n",
    "    openai_client = OpenAI(\n",
    "        organization=os.environ.get(\"OPENAI_ORG\"),\n",
    "        project=os.environ.get(\"OPENAI_PRJ\"),\n",
    "        )\n",
    "\n",
    "\n",
    "    # Run the OpenAI completion\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Extract the response content\n",
    "    response_content = response.choices[0].message.content\n",
    "    \n",
    "    # Display the question and AI-generated response\n",
    "    display(Markdown(f\"**Question:** {question}\"))\n",
    "    display(Markdown(f\"**AI Response:**\\n\\n{response_content}\"))\n",
    "    \n",
    "    # Execute the Python code within the response\n",
    "    execute_python_code(response_content)\n",
    "\n",
    "# Example usage\n",
    "file_path = 'electronic_sales_data.csv'\n",
    "description = \"This dataset contains sales transaction records for an electronics company.\"\n",
    "key_features = \"\"\"\n",
    "Customer ID: Unique identifier for each customer.\n",
    "Age: Age of the customer (numeric)\n",
    "Gender: Gender of the customer (Male or Female)\n",
    "Loyalty Member: (Yes/No) (Values change by time, so pay attention to who cancelled and who signed up)\n",
    "Product Type: Type of electronic product sold (e.g., Smartphone, Laptop, Tablet)\n",
    "SKU: a unique code for each product.\n",
    "Rating: Customer rating of the product (1-5 stars) (Should have no Null Ratings)\n",
    "Order Status: Status of the order (Completed, Cancelled)\n",
    "Payment Method: Method used for payment (e.g., Cash, Credit Card, Paypal)\n",
    "Total Price: Total price of the transaction (numeric)\n",
    "Unit Price: Price per unit of the product (numeric)\n",
    "Quantity: Number of units purchased (numeric)\n",
    "Purchase Date: Date of the purchase (format: YYYY-MM-DD)\n",
    "Shipping Type: Type of shipping chosen (e.g., Standard, Overnight, Express)\n",
    "Add-ons Purchased: List of any additional items purchased (e.g., Accessories, Extended Warranty)\n",
    "Add-on Total: Total price of add-ons purchased (numeric)\n",
    "\"\"\"\n",
    "question = \"What is the average sales amount for each month?\"\n",
    "ask_question_and_display_output(question, file_path, description, key_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year-Month  Average Sales Amount\n",
      "0     2023-09           2536.641000\n",
      "1     2023-10           2544.968551\n",
      "2     2023-11           2595.274956\n",
      "3     2023-12           2475.875413\n",
      "4     2024-01           3230.928487\n",
      "5     2024-02           3153.848218\n",
      "6     2024-03           3231.664711\n",
      "7     2024-04           3322.077443\n",
      "8     2024-05           3275.899868\n",
      "9     2024-06           3335.984787\n",
      "10    2024-07           3285.635757\n",
      "11    2024-08           3323.150946\n",
      "12    2024-09           3376.468579\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('electronic_sales_data_cleaned.csv')\n",
    "\n",
    "# Convert 'Purchase Date' to datetime\n",
    "df['Purchase Date'] = pd.to_datetime(df['Purchase Date'])\n",
    "\n",
    "# Extract year and month and create a new column\n",
    "df['Year-Month'] = df['Purchase Date'].dt.to_period('M')\n",
    "\n",
    "# Group by 'Year-Month' and calculate the mean of 'Total Price'\n",
    "monthly_avg_sales = df.groupby('Year-Month')['Total Price'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "monthly_avg_sales.columns = ['Year-Month', 'Average Sales Amount']\n",
    "\n",
    "print(monthly_avg_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer ID  Age Gender Loyalty Member Product Type      SKU  Rating  \\\n",
      "0         1000   53   Male             No   Smartphone  SKU1004       2   \n",
      "1         1000   53   Male             No       Tablet  SKU1002       3   \n",
      "2         1002   41   Male             No       Laptop  SKU1005       3   \n",
      "3         1002   41   Male            Yes   Smartphone  SKU1004       2   \n",
      "4         1003   75   Male            Yes   Smartphone  SKU1001       5   \n",
      "\n",
      "  Order Status Payment Method  Total Price  Unit Price  Quantity  \\\n",
      "0    Cancelled    Credit Card      5538.33      791.19         7   \n",
      "1    Completed         Paypal       741.09      247.03         3   \n",
      "2    Completed    Credit Card      1855.84      463.96         4   \n",
      "3    Completed           Cash      3164.76      791.19         4   \n",
      "4    Completed           Cash        41.50       20.75         2   \n",
      "\n",
      "  Purchase Date Shipping Type              Add-ons Purchased  Add-on Total  \n",
      "0    2024-03-20      Standard  Accessory,Accessory,Accessory         40.21  \n",
      "1    2024-04-20     Overnight                   Impulse Item         26.09  \n",
      "2    2023-10-17       Express                            NaN          0.00  \n",
      "3    2024-08-09     Overnight      Impulse Item,Impulse Item         60.16  \n",
      "4    2024-05-21       Express                      Accessory         35.56  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to inspect the dataframe's structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer ID            int64\n",
      "Age                    int64\n",
      "Gender                object\n",
      "Loyalty Member        object\n",
      "Product Type          object\n",
      "SKU                   object\n",
      "Rating                 int64\n",
      "Order Status          object\n",
      "Payment Method        object\n",
      "Total Price          float64\n",
      "Unit Price           float64\n",
      "Quantity               int64\n",
      "Purchase Date         object\n",
      "Shipping Type         object\n",
      "Add-ons Purchased     object\n",
      "Add-on Total         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the dataframe's column data types\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer ID                   int64\n",
      "Age                           int64\n",
      "Gender                       object\n",
      "Loyalty Member               object\n",
      "Product Type                 object\n",
      "SKU                          object\n",
      "Rating                        int64\n",
      "Order Status                 object\n",
      "Payment Method               object\n",
      "Total Price                 float64\n",
      "Unit Price                  float64\n",
      "Quantity                      int64\n",
      "Purchase Date        datetime64[ns]\n",
      "Shipping Type                object\n",
      "Add-ons Purchased            object\n",
      "Add-on Total                float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Replace 'date' with the name of your date column\n",
    "df['Purchase Date'] = pd.to_datetime(df['Purchase Date'], errors='coerce')\n",
    "\n",
    "# Verify the conversion\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Customer ID, Age, Gender, Loyalty Member, Product Type, SKU, Rating, Order Status, Payment Method, Total Price, Unit Price, Quantity, Purchase Date, Shipping Type, Add-ons Purchased, Add-on Total]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Identify rows where the date conversion failed\n",
    "invalid_dates = df[df['Purchase Date'].isna()]\n",
    "print(invalid_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('electronic_sales_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42629615.57\n",
      "Tokens Used: 613\n",
      "\tPrompt Tokens: 427\n",
      "\tCompletion Tokens: 186\n",
      "Total Cost (USD): $ 0.004925\n"
     ]
    }
   ],
   "source": [
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "from pandasai.helpers.openai_info import get_openai_callback\n",
    "\n",
    "llm = OpenAI(api_token=os.environ.get(\"OPENAI_API_KEY\"), model=model)\n",
    "ai_df = SmartDataframe(\"electronic_sales_data_cleaned.csv\", config={\"llm\": llm})\n",
    "\n",
    "try:\n",
    "    with get_openai_callback() as cb:\n",
    "        response = ai_df.chat(\"Calculate the total sales amount.\")\n",
    "        print(response)\n",
    "        print(cb)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. General Data Structure and Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataset, including column names, data types, and non-null counts\n",
    "df.info()\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicates_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Overview of Sales Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total sales revenue (assuming 'Sales_Amount' is the relevant column)\n",
    "total_sales = df['Sales_Amount'].sum()\n",
    "print(f\"Total Sales Revenue: ${total_sales:.2f}\")\n",
    "\n",
    "# Convert 'Date' column to datetime format for further analysis\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group by month and calculate total sales\n",
    "monthly_sales = df.resample('M', on='Date')['Sales_Amount'].sum()\n",
    "print(\"Monthly Sales Trend:\")\n",
    "print(monthly_sales)\n",
    "\n",
    "# Plot the monthly sales trend\n",
    "plt.figure(figsize=(10, 5))\n",
    "monthly_sales.plot()\n",
    "plt.title('Monthly Sales Trend')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Customer Behavior Insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of unique customers\n",
    "unique_customers = df['Customer_ID'].nunique()\n",
    "print(f\"Total Unique Customers: {unique_customers}\")\n",
    "\n",
    "# Calculate the frequency of purchases per customer\n",
    "purchase_frequency = df['Customer_ID'].value_counts()\n",
    "print(\"Top 5 most frequent buyers:\")\n",
    "print(purchase_frequency.head(5))\n",
    "\n",
    "# Calculate the average time interval between purchases for each customer\n",
    "customer_avg_interval = df.groupby('Customer_ID')['Date'].apply(lambda x: x.sort_values().diff().mean())\n",
    "print(\"Average purchase intervals (in days) for the top 5 customers:\")\n",
    "print(customer_avg_interval.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Product and Category Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by 'Product_ID' to find top-selling products by quantity\n",
    "top_selling_products = df.groupby('Product_ID')['Quantity'].sum().sort_values(ascending=False)\n",
    "print(\"Top 5 selling products by quantity:\")\n",
    "print(top_selling_products.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Sales Trends and Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by 'Region' and sum 'Sales_Amount' (assuming 'Region' is a column)\n",
    "sales_by_region = df.groupby('Region')['Sales_Amount'].sum().sort_values(ascending=False)\n",
    "print(\"Total sales by region:\")\n",
    "print(sales_by_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Pricing and Discounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between 'Product_Price' and 'Quantity'\n",
    "correlation = df['Product_Price'].corr(df['Quantity'])\n",
    "print(f\"Correlation between product price and quantity sold: {correlation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7. Potential Issues and Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers in 'Sales_Amount' using the IQR method\n",
    "Q1 = df['Sales_Amount'].quantile(0.25)\n",
    "Q3 = df['Sales_Amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df[(df['Sales_Amount'] < (Q1 - 1.5 * IQR)) | (df['Sales_Amount'] > (Q3 + 1.5 * IQR))]\n",
    "print(f\"Number of outliers in Sales Amount: {outliers.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Customer Segmentation and Retention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple customer segmentation based on purchase frequency\n",
    "df['Purchase_Frequency'] = df['Customer_ID'].map(purchase_frequency)\n",
    "bins = [0, 1, 5, 10, 50, df['Purchase_Frequency'].max()]\n",
    "labels = ['One-time', 'Occasional', 'Frequent', 'Loyal', 'Super Loyal']\n",
    "df['Customer_Segment'] = pd.cut(df['Purchase_Frequency'], bins=bins, labels=labels)\n",
    "segment_counts = df['Customer_Segment'].value_counts()\n",
    "print(\"Customer segments based on purchase frequency:\")\n",
    "print(segment_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 9. Automated Insights with pandas ai and Azure OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Azure OpenAI for pandas_ai (replace with your own API key and endpoint)\n",
    "openai = AzureOpenAI(api_key='YOUR_API_KEY', endpoint='YOUR_API_ENDPOINT')\n",
    "pandas_ai = PandasAI(llm=openai)\n",
    "\n",
    "# Use pandas_ai to interactively query the data\n",
    "response = pandas_ai(df, \"What is the average sales amount for each month?\")\n",
    "print(\"Pandas AI Response:\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
